{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61294325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from train import evaluate\n",
    "from models import setup_model\n",
    "from datasets import CatCamDataset\n",
    "from utils import set_random_seeds, load_model, measure_pytorch_time, measure_tflite_time, calculate_metrics, show_metrics, inference_tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585eb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install onnx\n",
    "!pip install onnx2tf\n",
    "!pip install ai_edge_litert\n",
    "!pip install sng4onnx\n",
    "!pip install onnx_graphsurgeon\n",
    "!pip install tflite-runtime\n",
    "\n",
    "!pip uninstall protobuf\n",
    "!pip install protobuf==4.25.3\n",
    "\n",
    "!pip uninstall numpy -y\n",
    "!pip install numpy==1.26.4\n",
    "\n",
    "!pip uninstall tensorflow tensorflow-cpu tensorflow-gpu -y\n",
    "!pip install tensorflow==2.15.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be6683",
   "metadata": {},
   "source": [
    "conversion onnx->tf using onnx2tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "\n",
    "model_dir = \"/content/saved_models\"\n",
    "model_name = \"efficientnet_b0\"\n",
    "model_filename = model_name + \".pt\"\n",
    "pruned_model_filename = model_name + \"_pruned.pt\"\n",
    "quantized_model_filename = model_name + \"_quantized.pt\"\n",
    "tflite_model_filename = model_name + \".tflite\"\n",
    "\n",
    "original_model_filepath = os.path.join(model_dir, model_filename)\n",
    "pruned_model_filepath = os.path.join(model_dir, pruned_model_filename)\n",
    "quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
    "tflite_model_filepath = os.path.join(model_dir, tflite_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/content/catcam\"\n",
    "batch_size = 1\n",
    "\n",
    "#remove center crop??\n",
    "val_aug_args = {\n",
    "    \"imgsz\" : 224,\n",
    "    \"center_crop_size\" : 224,\n",
    "    \"normalize_mean\": [0.485, 0.456, 0.406],\n",
    "    \"normalize_std\": [0.229, 0.224, 0.225]\n",
    "}\n",
    "\n",
    "val_dataset = CatCamDataset(root_dir, val_aug_args, mode=\"val\")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_dataset = CatCamDataset(root_dir, val_aug_args, mode=\"test\")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd956a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seeds(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022ce67",
   "metadata": {},
   "source": [
    "# Conversion to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to val data\n",
    "def representative_dataset():\n",
    "    global val_dataloader\n",
    "    for image, label in val_dataloader:\n",
    "        yield [image.permute(0, 2, 3, 1).numpy().astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911659ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model that was converted from onnx to tf using onnx2tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"model_qat\")\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.allow_custom_ops = False\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329dde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving\n",
    "with open(tflite_model_filepath, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model was succesfully converted to int8!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43918846",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d06066",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_model = LogisticRegression()\n",
    "tflite_logits, labels = inference_tflite_model(tflite_model_filepath=tflite_model_filepath)\n",
    "calibration_model.fit(tflite_logits, labels)\n",
    "\n",
    "#calibration coefs\n",
    "#logit -> sigmoid(a*logit+b)\n",
    "a = calibration_model.coef_[0][0]\n",
    "b = calibration_model.intercept_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6692c",
   "metadata": {},
   "source": [
    "# Speed comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading torch models\n",
    "init_model = setup_model(model_name, pretrained=False)\n",
    "\n",
    "original_model = load_model(init_model, original_model_filepath, cpu_device)\n",
    "pruned_model = load_model(init_model, pruned_model_filepath, cpu_device)\n",
    "quantized_model = load_model(init_model, quantized_model_filepath, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 150\n",
    "\n",
    "original_time = measure_pytorch_time(original_model, num_runs=num_runs)\n",
    "pruned_time = measure_pytorch_time(pruned_model, num_runs=num_runs)\n",
    "quantized_time = measure_pytorch_time(quantized_model, num_runs=num_runs)\n",
    "\n",
    "tflite_time = measure_tflite_time(tflite_model, num_runs=num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d270fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torchscript: \")\n",
    "print(f\"Original model: {original_time:6.2f}\")\n",
    "print(f\"Pruned_model: {pruned_time:6.2f}\")\n",
    "print(f\"QAT model: {quantized_time:6.2f}\")\n",
    "\n",
    "print(\"\\nTensorflow Lite:\")\n",
    "print(f\"TFLite model: {tflite_time:6.2f}\")\n",
    "\n",
    "print(\"=\" * 45)\n",
    "improvement = (original_time - tflite_time) / original_time * 100\n",
    "print(f\"Improvement over original: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6b9a4",
   "metadata": {},
   "source": [
    "# Accuracy metrics comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch test metric calculation\n",
    "original_model_metrics = evaluate(original_model, test_dataloader, cpu_device)\n",
    "pruned_model_metrics = evaluate(pruned_model, test_dataloader, cpu_device)\n",
    "quantized_model_metrics = evaluate(quantized_model, test_dataloader, cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_logits, labels = inference_tflite_model(tflite_model_filepath, test_dataloader, a, b)\n",
    "tflite_model_metrics = calculate_metrics(tflite_logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add calibration??\n",
    "show_metrics(original_model, \"Original model\")\n",
    "show_metrics(pruned_model_metrics, \"Pruned model\")\n",
    "show_metrics(quantized_model_metrics, \"Quantized model\")\n",
    "show_metrics(tflite_model_metrics, \"TFLite model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f89b36",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
