{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "XW7p5gaxYLHo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "from train import train_loop, evaluate\n",
        "from utils import fuse_model, show_metrics, set_random_seeds, save_model, load_model,  \n",
        "from models import setup_model, QuantizedModel\n",
        "from datasets import create_url_df, CatCamDataset\n",
        "from pruning import measure_global_sparsity, iterative_pruning_finetuning, remove_parameters\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#init parameters\n",
        "random_seed = 42\n",
        "cuda_device = torch.device(\"cuda:0\")\n",
        "cpu_device = torch.device(\"cpu:0\")\n",
        "\n",
        "model_dir = \"saved_models\"\n",
        "model_name = \"mobilenet_v3_small\"\n",
        "model_filename = model_name + \".pt\"\n",
        "model_filename_prefix = \"pruned_model\"\n",
        "pruned_model_filename = model_name + \"_pruned.pt\"\n",
        "quantized_model_filename = model_name + \"quantized.pt\"\n",
        "model_filepath = os.path.join(model_dir, model_filename)\n",
        "pruned_model_filepath = os.path.join(model_dir, pruned_model_filename)\n",
        "quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
        "\n",
        "root_dir = \"/catcam\" #data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train parameters\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "l1_regularization_strength = 0\n",
        "l2_regularization_strength = 1e-4\n",
        "learning_rate = 1e-3\n",
        "learning_rate_decay = 1\n",
        "early_stopping_patience = 7\n",
        "\n",
        "train_aug_args = {\n",
        "    \"imgsz\": 224,\n",
        "    \"hflip_prob\": 0.5,\n",
        "    \"rotation_degrees\": 15,\n",
        "    \"perspective_scale\": 0.2,\n",
        "    \"perspective_prob\": 0.3,\n",
        "    \"brightness_jitter\": 0.15,\n",
        "    \"contrast_jitter\": 0.1,\n",
        "    \"saturation_jitter\": 0.2,\n",
        "    \"hue_jitter\": 0.02,\n",
        "    \"grayscale_prob\": 0.05,\n",
        "    \"gaussian_blur_kernel\": (3, 3),\n",
        "    \"gaussian_blur_sigma\": (0.1, 0.5),\n",
        "    \"random_erase_prob\": 0.2,\n",
        "    \"random_erase_scale\": (0.02, 0.08),\n",
        "    \"normalize_mean\": [0.485, 0.456, 0.406],\n",
        "    \"normalize_std\": [0.229, 0.224, 0.225]\n",
        "},\n",
        "\n",
        "val_aug_args = {\n",
        "    \"imgsz\" : 224,\n",
        "    \"center_crop_size\" : 224,\n",
        "    \"normalize_mean\": [0.485, 0.456, 0.406],\n",
        "    \"normalize_std\": [0.229, 0.224, 0.225]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_random_seeds(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#prepairing data\n",
        "cat_urls_path = os.path.join(root_dir, \"cat_urls.txt\")\n",
        "no_cat_urls_path = os.path.join(root_dir, \"no_cat_urls.txt\")\n",
        "url_df = create_url_df(cat_urls_path, no_cat_urls_path)\n",
        "\n",
        "train, val, test = np.split(url_df.sample(frac=1), [int(.6*len(url_df)), int(.8*len(url_df))])\n",
        "\n",
        "train_dataset = CatCamDataset(train, root_dir, train_aug_args)\n",
        "val_dataset = CatCamDataset(val, root_dir, val_aug_args)\n",
        "test_dataset = CatCamDataset(test, root_dir, val_aug_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#setup model\n",
        "model = setup_model(\"mobilenet_v3_small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#evaluation\n",
        "test_metrics = evaluate(model, test_dataloader, cuda_device)\n",
        "show_metrics(test_metrics)\n",
        "sparsity = measure_global_sparsity(model, conv2d_use_mask=True)\n",
        "print(f\"Sparsity: {sparsity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pruning\n",
        "print(\"Iterative pruning + Fine-Tuning...\")\n",
        "\n",
        "pruned_model = copy.deepcopy(model)\n",
        "\n",
        "iterative_pruning_finetuning(\n",
        "        model=pruned_model,\n",
        "        train_loader=train_dataloader,\n",
        "        test_loader=test_dataloader,\n",
        "        device=cuda_device,\n",
        "        learning_rate=learning_rate,\n",
        "        learning_rate_decay=learning_rate_decay,\n",
        "        l1_regularization_strength=l1_regularization_strength,\n",
        "        l2_regularization_strength=l2_regularization_strength,\n",
        "        conv2d_prune_amount=0.98,\n",
        "        linear_prune_amount=0,\n",
        "        num_iterations=1,\n",
        "        num_epochs_per_iteration=500,\n",
        "        model_filename_prefix=model_filename_prefix,\n",
        "        model_dir=model_dir,\n",
        "        grouped_pruning=True)\n",
        "\n",
        "remove_parameters(model=pruned_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#evaluation after pruning\n",
        "test_metrics = evaluate(model, test_dataloader, cuda_device)\n",
        "show_metrics(test_metrics)\n",
        "sparsity = measure_global_sparsity(model, conv2d_use_mask=True)\n",
        "print(f\"Sparsity: {sparsity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#saving pruned model\n",
        "save_model(model, model_dir, model_filename=pruned_model_filename)\n",
        "model = load_model(model, model_filepath, cuda_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#fusing model\n",
        "model.to(cpu_device)\n",
        "fused_model = fuse_model(model, model_name)\n",
        "fused_model = copy.deepcopy(model)\n",
        "\n",
        "model.train()\n",
        "fused_model.train()\n",
        "\n",
        "model.eval()\n",
        "fused_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model quantization (QAT)\n",
        "quantized_model = QuantizedModel(model_fp32=fused_model)\n",
        "quantization_config = torch.quantization.get_default_qconfig(\"qnnpack\")\n",
        "quantized_model.qconfig = quantization_config\n",
        "torch.quantization.prepare_qat(quantized_model, inplace=True)\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        weight_decay=l2_regularization_strength\n",
        "    )\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "print(\"Training QAT Model...\")\n",
        "\n",
        "quantized_model.train()\n",
        "qat_history = train_loop(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, cuda_device, epochs, early_stopping_patience) #to visualize\n",
        "quantized_model.to(cpu_device)\n",
        "\n",
        "quantized_model = torch.quantization.convert(quantized_model, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#converting to onnx\n",
        "quantized_model.eval()\n",
        "\n",
        "dummy_input = torch.rand(1, 3, 224, 224)\n",
        "\n",
        "#saving\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    quantized_model_filepath,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
        "    opset_version=12,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#loading and converting to tf\n",
        "onnx_model = onnx.load(\"efficientnet_b0.onnx\")\n",
        "\n",
        "tf_rep = prepare(onnx_model)\n",
        "\n",
        "tf_rep.export_graph(\"efficientnet_b0_savedmodel\")\n",
        "\n",
        "#converting to tflite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"efficientnet_b0_savedmodel\")\n",
        "\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "#converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "#saving\n",
        "with open(\"efficientnet_b0_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#load tflite model\n",
        "#evaluate\n",
        "#calculate & show sparsity, inference latency (fp32, int8 on cpu and cuda)\n",
        "\n",
        "#тут торчскрипт но нам нужен tflite (onnx?)\n",
        "\"\"\"save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
        "\n",
        "quantized_jit_model = load_torchscript_model(model_filepath=quantized_model_filepath, device=cpu_device)\n",
        "\n",
        "test_metrics = evaluate(model, test_dataloader, cuda_device)\n",
        "show_metrics(test_metrics)\n",
        "sparsity = measure_global_sparsity(model, conv2d_use_mask=True)\n",
        "print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
        "int8_cpu_inference_latency = measure_inference_latency(model=quantized_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
        "int8_jit_cpu_inference_latency = measure_inference_latency(model=quantized_jit_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
        "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
        "\n",
        "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
        "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
        "print(\"INT8 CPU Inference Latency: {:.2f} ms / sample\".format(int8_cpu_inference_latency * 1000))\n",
        "print(\"INT8 JIT CPU Inference Latency: {:.2f} ms / sample\".format(int8_jit_cpu_inference_latency * 1000))\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s0Ntg-IaaX8b",
        "outputId": "22e8b5d6-e1df-4b99-c66d-097f4775965d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nSteps to QAT:\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Steps to QAT:\n",
        "pretrained model -> transfering to cpu ->\n",
        "-> fused model -> some prepairings (???) -> (pseudo) quntazied model ->\n",
        "-> some prepairings -> training quantized model -> transfering quantized model to cpu ->\n",
        "-> convertartion (quantization) -> saving model\n",
        "\n",
        "Steps to pruning:\n",
        "Just prune during the training basing on rule\n",
        "\n",
        "How to combine them?\n",
        "We should use pruning while training (pseudo) quantized model\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OlTpYBKmekke"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
